---
title: "03_RSpatial_Final_Project_Bernardin_2021"
author: "Jessica Bernardin"
date: "12/9/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
library(tidycensus)
library(tidyverse)
library(pander)
library(sf)
library(terra)
library(units)
library(purrr)
library(sp)
library(profvis)
library(ggmap)
library(cartogram)
library(patchwork)
library(tmap)
library(viridis)
library(tigris)
library(gridExtra)
library(plotly)
library(Rcpp)
library(raster)
library(rgbif)
library(maps)
library(dplyr)
library(cowplot)
library(ggspatial)
library(dismo)
library(rgdal) 
library(rgeos)
library(randomForest)
library(dplyr)
library(devtools)
install_github("jhollist/elevatr")
library(elevatr)
library(rJava)
library(ISLR)
library(boot)
library(pROC)

```


## Goals for the Assignment

1.  Fit both a global and reduced model for:
- a logistic regression
- a random forest analysis
- a maxent analysis 

2.  Predictor Variables:
- Global Model = temperature, precipitation, elevation, max temperature, min temperature
- Reduced Model = elevation, precipitation

3.  Generate AUC for all 6 models

4.  Generate confusion matrix for best model

5.  Check for model fit using k-fold cross-validation

6.  Plot the spatial predictions from the best model

7.  Format the project as a Rmarkdown manuscript:
- Introduction (questions, interests, hypothesis) 1-2 paragraph
- Methods (justify assumptions and modifications) with code chunks
- Results
- Discussion (interpret results and best model and why) 2-3 paragraphs


## Introduction

*Sarrecenia purpurea* are a type of carnivorous plant that uses their passive pit traps to capture insect prey.  Prey are attracted to the nectar excreted by the plant along the rim of the pitcher.  Insects fall in and are digested by the aquatic community of invertebrates, bacteria, and fungi that inhabit the plant's traps.  These plants are distributed along the Eastern United States, from northern Florida to Canada, and west along the Great Lakes.  Despite this wide distribution, they are specialized in the types of environments they can inhabit, specially oligotrophic bogs and fens.  

The goal of this project was to gain experiment working with spatial data and analysis in R.  Species occurrence data were used as response variables in order to determine which environmental variables might be driving species distribution.  We understand that there are likely variables not included in this project that more accurately explain their occurrence patterns (soil type, soil moisture, proximity to wetlands, soil pH), however for this project the goal was to work with general climate data in order to build a fundamental knowledge of building spatial data sets, visualizing spatial data, and analyzing spatial data in R.

## Methods

### Data

Plant point occurrence data was downloaded using the `rgbif` package which pulls observations data from iNaturalist.  These data are citizen science observations and could also include points for plants present in herbarium, botanical gardens, planted as an ornamental.  Climatic variables used as predictors were extracted from world climate data using the raster package in R.  Elevation data for each pitcher observation was downloaded using the `elevatr` package.  The pitcher observation points were filtered to include only observations in the contiguous United States and predictor variables were extracted for each observation.  A data frame was created to hold this data, along with 10,000 randomly generated background points in the US and their extracted predictor variables.

### Analysis

Response and predictor variables were modeled using three different model types: logistic regression with logit link, random forest analysis for classification (presence/absence as factors), and maximum entropy model.  Both a global and restricted data set was fit for each model, the global model contained all 5 predictor variables (mean annual temperature, mean annual precipitation, max annual temperature, min annual temperature, and elevation).  The restricted model contained only two of the predictor variables.  Area under the curve (AUC) was used as a measure of model fit along with k-fold (k = 10) cross validation to ensure that we weren't overfitting our model.  Lastly, a confusion matrix was built for the best fitting model (highest AUC) in order to determine the number of correct and incorrect predictions from that model.


```{r getthedata}

#####rasters of environmental variables
r <- getData("worldclim",var="bio",res=10)
#temp mean annual
temp.rast <- r[[1]]
names(temp.rast) <- "temp"

#mean annual precipitation
precip.rast <- r[[12]]
names(precip.rast) <- "prec"

#max temp warmest month
maxtem.rast <- r[[5]]
names(maxtem.rast) <- "max_temp"

#min temp coldest month
mintem.rast <- r[[6]]
names(mintem.rast) <- "min_temp"

#stack 'em up!
environ.stack <- stack(temp.rast, precip.rast, maxtem.rast, mintem.rast)


# download GBIF occurrence data
sp <- c("Sarracenia purpurea")

gbif_data <- rgbif::occ_data(scientificName = sp, hasCoordinate = TRUE, limit = 20000)

# get the columns that matter for mapping and cleaning the occurrence data:
spurp_data <- gbif_data$data[ , c("decimalLongitude", "decimalLatitude", "individualCount", "occurrenceStatus", "coordinateUncertaintyInMeters", "institutionCode", "references")]
head(spurp_data)

# map the occurrence data
maps::map("world", xlim = range(spurp_data$decimalLongitude), ylim = range(spurp_data$decimalLatitude))
points(spurp_data[ , c("decimalLongitude", "decimalLatitude")], pch = ".")

class(spurp_data)
spurp_data.sf <- st_as_sf(spurp_data, coords = c("decimalLongitude", "decimalLatitude"), crs = "EPSG:4326")
spurp_data.sf <- spurp_data.sf %>% 
  st_transform(., crs = st_crs(r))


#get shapefile for united states with counties
co <- counties(state = NULL)

#take out places really far away
co <- co[!co$STATEFP == "02",]#Alaska
co <- co[!co$STATEFP == "60",] #American Samoa
co <- co[!co$STATEFP == "72",]# Puerto Rico
co <- co[!co$STATEFP == "78",] # Virgin Islands
co <- co[!co$STATEFP == "66",] # Guam
co <- co[!co$STATEFP == "15",] #HI
co <- co[!co$STATEFP == "69",] # Northern Mariana Islands

#plot counties
gg <- ggplot()
gg <- gg + geom_sf(data = co, color="black",
                   fill="white", size=0.25)
gg
#transform counties to rasters
co <- co %>% 
  st_transform(., crs = st_crs(r))


#extract climate data for pitcher locations
temp.extract <- terra::extract(temp.rast, spurp_data.sf, fun = mean, na.rm=TRUE)
spurp_data.sf$temp <- temp.extract

precip.extract <- terra::extract(precip.rast, spurp_data.sf, fun = mean, na.rm=TRUE)
spurp_data.sf$precip <- precip.extract

maxtemp.extract <- terra::extract(maxtem.rast, spurp_data.sf, fun = mean, na.rm=TRUE)
spurp_data.sf$max_temp <- maxtemp.extract

mintemp.extract <- terra::extract(mintem.rast, spurp_data.sf, fun = mean, na.rm=TRUE)
spurp_data.sf$min_temp <- mintemp.extract


#trim spurp data to the united states only
boundary <- nation(resolution = '20m')
extent(boundary)
#class      : Extent 
#xmin       : -179.1743 
#xmax       : 179.7739 
#ymin       : 17.91377 
#ymax       : 71.35256

boundary <- boundary %>% 
  st_transform(., crs = st_crs(r))

spurp_data.sf <- st_intersection(spurp_data.sf, boundary)
plot(st_geometry(spurp_data.sf))

#get an elevation raster for the US for the maxent model
#elevation <- get_elev_raster(boundary, z = 4) #keep getting an error that the url did not return tif
```



```{r elv, cache=TRUE}
#get elevation data for pitcher plant locations
#this takes a while (5 min)
sp_elev_epqs <- get_elev_point(spurp_data.sf, src = "aws")
sp_elev_epqs <- sp_elev_epqs %>% 
  st_transform(., crs = st_crs(r))
#clean this up and add a presence column
sp <- sp_elev_epqs[c(6:9,13,15)]
sp$pres <- "1"

spurp_data.sf$pres <- "1"
pres.pts <- as(spurp_data.sf, Class = "Spatial")
pres.pts <- pres.pts[,-(1:12)]
x <- pres.pts[,-(1)]
x <- x[,-(3)]

#make some random points in the US
#set the extent for the pitcher plant data to be where we collect bg points
e <- extent(sp_elev_epqs)
bg <- randomPoints(maxtem.rast, 10000, ext=e)
bg <- as.data.frame(bg)
class(bg)
bg.sf <- st_as_sf(bg, coords = c("x", "y"), crs = "EPSG:4326")

bg.sf <- bg.sf %>% 
  st_transform(., crs = st_crs(r))

bg.sf$pres <- "0"

#get elevation for background points
bg.sf.e <- get_elev_point(bg.sf, src = "aws")
bg.el <- as.data.frame(bg.sf.e)
bg.el$ID <- rownames(bg.el)
#extract background point values from rasters of predictor variables
bg.df <- extract(environ.stack, bg.sf.e, df = TRUE)

bg.df.all <- merge(bg.df, bg.el, by= "ID")

#these are the absence points
bg.df.all$pres <- "0"

#add our absence data to our presence data
names(bg.df.all)
names(sp)
names(bg.df.all) <- c('ID', 'temp', 'precip', 'max_temp', 'min_temp', 'pres', 'elevation', 'el_units', 'geometry')

bg.df.all <- as.data.frame(bg.df.all)
bg.df.all <- subset(bg.df.all, select = -c(ID, el_units))
sp <- as.data.frame(sp)

#COMBINE PRES AND SIMULATED ABS POINTS!
presabs.df <- rbind(sp, bg.df.all)

presabs.df$pres <- as.factor(presabs.df$pres)

#scale the predictors
presabs.df[,1:5] <- scale(presabs.df[,1:5])
pairs(presabs.df[,1:5])
```


## Results

### Logistic Regression Models



```{r logreg}

presabs.df.nona <- drop_na(presabs.df)

###GLOBAL MODEL
#model using all the predictors
logistic.global <- glm(pres~temp + precip + max_temp + min_temp + elevation, family=binomial(link="logit"), data=presabs.df.nona)
logistic.global
summary(logistic.global)

#calculate probability of pres/abs for each predic. in test dataset
predicted.1 <- predict(logistic.global, presabs.df.nona, type="response")
#calculate AUC
pROC::auc(presabs.df.nona$pres, predicted.1) #AUC = 0.882

# KFCV 
cv.err1 <- cv.glm(presabs.df.nona,logistic.global, K = 10)
cv.err1$delta #0.1347364 0.1347278



#REDUCED MODEL
#model using two of the predictors
logistic.two <- glm(pres ~ precip + elevation, family=binomial(link="logit"), data=presabs.df.nona)
logistic.two
summary(logistic.two)

#calculate probability of default for each individual in test dataset
predicted.2 <- predict(logistic.two, presabs.df.nona, type="response")
#calculate AUC
pROC::auc(presabs.df.nona$pres, predicted.2) #AUC = 0.6912

# KFCV 
cv.err2 <- cv.glm(presabs.df.nona,logistic.two, K = 10)
cv.err2$delta #0.2021303 0.2021256

cv.err2


#CONFUSION MATRIX
#global
#confusionMatrix(presabs.df.nona$pres, predicted.2)

```

### Random Forest Models



```{r RANFOR}
#GLOBAL MODEL
#random forest regression
glob.model <- pres ~ temp + precip + max_temp + min_temp + elevation
rf1 <- randomForest(glob.model, data=presabs.df.nona, na.rm = TRUE)
varImpPlot(rf1)

#AUC
rf1.roc<-roc(presabs.df.nona$pres,rf1$votes[,2])
plot(rf1.roc)
auc(rf1.roc) #0.9748

# KFCV 
#divide up the predictor and response
a <- presabs.df.nona
a$pres <- NULL
a$geometry <- NULL
b <- presabs.df.nona$pres
rf1.cv <- randomForest::rfcv(a, b, cv.fold=10)
with(rf1.cv, plot(n.var, error.cv))

#REDUCED MODEL
#random forest regression
reg.model <- pres ~ precip + elevation
rf2 <- randomForest(reg.model, data = presabs.df.nona)
varImpPlot(rf2)

#AUC
rf2.roc<-roc(presabs.df.nona$pres,rf2$votes[,2])
plot(rf2.roc)
auc(rf2.roc) #0.9181

# KFCV 
#divide up the predictor and response
c <- presabs.df.nona
c$pres <- NULL
c$geometry <- NULL
c$temp <- NULL
c$min_temp <- NULL
c$max_temp <- NULL
b <- presabs.df.nona$pres
rf2.cv <- randomForest::rfcv(c, b, cv.fold=10)
with(rf2.cv, plot(n.var, error.cv))


```

```{r confmat, eval=FALSE}

# confusion matrix for my best model (global random forest)
nogeo <- presabs.df.nona
nogeo$geometry <- NULL
y_pred <- predict(rf1, newdata = presabs.df.nona[-6])
y_pred
nogeo[,6]
cm <- table(nogeo[,6], y_pred)
cm

#false neg = 65
#false pos = 2
#correct = 7983 + 4829 = 12812/12879 = .99479773 pretty good!
```

### Maximum Entropy Models




```{r MAXENT}
#GLOBAL MODEL
max.fit1 <- maxent(environ.stack, x, bg)
plot(max.fit1)
response(max.fit1)

#evaluate model
e1 <- evaluate(max.fit1, p = x, a = bg, x = environ.stack)
e1 #0.9182098
plot(e1, 'ROC')


#REDUCED MODEL
short.stack <- stack(precip.rast, temp.rast)

max.fit2 <- maxent(short.stack, x, bg)
plot(max.fit2)
response(max.fit2)

#evaluate model
e2 <- evaluate(max.fit2, p = x, a = bg, x = short.stack)
e2 #0.8906049
plot(e2, 'ROC')

```



```{r kfcv, eval=FALSE}
#KFCV for maxent models
pres.x <- presabs.df.nona[presabs.df.nona[,7] == 1, 1:5]
back.x <- presabs.df.nona[presabs.df.nona[,7] == 0, 1:5]


eMAX<-list()

folds <- 10

kfold_pres <- kfold(pres.x, folds)
kfold_back <- kfold(back.x, folds)

install.packages("maxnet")
library(maxnet)
for (i in 1:folds) {
  train <- pres.x[kfold_pres!= i,]
  test <- pres.x[kfold_pres == i,]
  backTrain<-back.x[kfold_back!=i,]
  backTest<- back.x[kfold_back==i,]
  dataTrain<-rbind(train,backTrain)
  dataTest<-rbind(test,backTest)
  maxnet_eval <- maxnet(dataTrain$pres, dataTrain[,1:5])
  eMAX[[i]] <- evaluate(p=dataTest[which(dataTest$pres==1),],a=dataTest[which(dataTest$pres==0),], maxnet_eval)
  plot(eMAX[[i]],'ROC')
  
}
##Error in glmnet::glmnet(x = mm, y = as.factor(p), family = "binomial",  : 
##number of elements in weights (0) not equal to the number of rows of x (11591)



```

```{r plot, eval=FALSE}

#Best AUC was reported for the global random forest model (0.98)
prRF <- predict(environ.stack, rf1, type="prob",index=2, na.action = na.omit)

par(mfrow=c(1,2))
plot(prRF, main='Random Forest Prediction')


```

Best AUC was reported for the global random forest model (0.98)
