---
title: "03_RSpatial_Final_Project_Bernardin_2021"
author: "Jessica Bernardin"
date: "12/9/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, message=FALSE}
library(tidycensus)
library(tidyverse)
library(pander)
library(sf)
library(terra)
library(units)
library(purrr)
library(sp)
library(profvis)
library(ggmap)
library(cartogram)
library(patchwork)
library(tmap)
library(viridis)
library(tigris)
library(gridExtra)
library(plotly)
library(Rcpp)
library(raster)
library(rgbif)
library(maps)
library(dplyr)
library(cowplot)
library(ggspatial)
library(dismo)
library(rgdal) 
library(rgeos)
library(randomForest)
library(dplyr)
library(devtools)
#install_github("jhollist/elevatr")
library(elevatr)
library(rJava)
library(ISLR)
library(boot)
library(pROC)
#devtools::install_github("MI2DataLab/randomForestExplainer")
library(randomForestExplainer)
```


## Goals for the Assignment

1.  Fit both a global and reduced model for:

- a logistic regression
- a random forest analysis
- a maxent analysis 

2.  Predictor Variables:

- Global Model = temperature, precipitation, elevation, max temperature, min temperature
- Reduced Model = elevation, precipitation

3.  Generate AUC for all 6 models

4.  Generate confusion matrix for best model

5.  Check for model fit using k-fold cross-validation

6.  Plot the spatial predictions from the best model

7.  Format the project as a Rmarkdown manuscript:

- Introduction (questions, interests, hypothesis) 1-2 paragraph
- Methods (justify assumptions and modifications) with code chunks
- Results
- Discussion (interpret results and best model and why) 2 paragraphs


## Introduction

*Sarrecenia purpurea* are a type of carnivorous plant that uses their passive pit traps to capture insect prey.  Prey are attracted to the nectar excreted by the plant along the rim of the pitcher.  Insects fall in and are digested by the aquatic community of invertebrates, bacteria, and fungi that inhabit the plant's traps.  These plants are distributed along the Eastern United States, from northern Florida to Canada, and west along the Great Lakes.  Despite this wide distribution, they are specialized in the types of environments they can inhabit, specially oligotrophic bogs and fens.  

The goal of this project was to gain experiment working with spatial data and analysis in R.  Species occurrence data were used as response variables in order to determine which environmental variables might be driving species distribution.  We understand that there are likely variables not included in this project that more accurately explain their occurrence patterns (soil type, soil moisture, proximity to wetlands, soil pH), however for this project the goal was to work with general climate data in order to build a fundamental knowledge of building spatial data sets, visualizing spatial data, and analyzing spatial data in R.

## Methods

### Data

Plant point occurrence data was downloaded using the `rgbif` package which pulls observations data from iNaturalist.  These data are citizen science observations and could also include points for plants present in herbarium, botanical gardens, planted as an ornamental.  Climatic variables used as predictors were extracted from world climate data using the raster package in R.  Elevation data for each pitcher observation was downloaded using the `elevatr` package.  The pitcher observation points were filtered to include only observations in the contiguous United States and predictor variables were extracted for each observation.  A data frame was created to hold this data, along with 10,000 randomly generated background points in the US and their extracted predictor variables.

### Analysis

Response and predictor variables were modeled using three different model types: logistic regression with logit link, random forest analysis for classification (presence/absence as factors), and maximum entropy model.  Both a global and restricted data set was fit for each model, the global model contained all 5 predictor variables (mean annual temperature, mean annual precipitation, max annual temperature, min annual temperature, and elevation).  The restricted model contained only two of the predictor variables.  Area under the curve (AUC) was used as a measure of model fit along with k-fold (k = 10) cross validation to ensure that we weren't overfitting our model.  Lastly, a confusion matrix was built for the best fitting model (highest AUC) in order to determine the number of correct and incorrect predictions from that model.


```{r getthedata}

#####rasters of environmental variables
r <- getData("worldclim",var="bio",res=10)
#temp mean annual
temp.rast <- r[[1]]
names(temp.rast) <- "temp"

#mean annual precipitation
precip.rast <- r[[12]]
names(precip.rast) <- "prec"

#max temp warmest month
maxtem.rast <- r[[5]]
names(maxtem.rast) <- "max_temp"

#min temp coldest month
mintem.rast <- r[[6]]
names(mintem.rast) <- "min_temp"

#trim  data to the united states only
boundary <- nation(resolution = '20m')
extent(boundary)
#class      : Extent 
#xmin       : -179.1743 
#xmax       : 179.7739 
#ymin       : 17.91377 
#ymax       : 71.35256

boundary <- boundary %>% 
  st_transform(., crs = st_crs(r))

e <- extent(-123.7791, -66.9675, 20, 50)

#get an elevation raster for the US for the maxent model
elevation <- elevatr::get_elev_raster(boundary, z = 4) 
elevation <- projectRaster(elevation, crs = crs(r))

elevation.crop <- crop(elevation, e)

#stack 'em up!
rs <- stack(temp.rast, precip.rast, maxtem.rast, mintem.rast)
r1 <- resample(rs,elevation.crop, method='ngb')
environ.stack <- stack(r1,elevation.crop)

# download GBIF occurrence data
sp <- c("Sarracenia purpurea")

gbif_data <- rgbif::occ_data(scientificName = sp, hasCoordinate = TRUE, limit = 20000)

# get the columns that matter for mapping and cleaning the occurrence data:
spurp_data <- gbif_data$data[ , c("decimalLongitude", "decimalLatitude", "individualCount", "occurrenceStatus", "coordinateUncertaintyInMeters", "institutionCode", "references")]

# map the occurrence data
maps::map("world", xlim = range(spurp_data$decimalLongitude), ylim = range(spurp_data$decimalLatitude))
points(spurp_data[ , c("decimalLongitude", "decimalLatitude")], pch = ".")

spurp_data.sf <- st_as_sf(spurp_data, coords = c("decimalLongitude", "decimalLatitude"), crs = "EPSG:4326")
spurp_data.sf <- spurp_data.sf %>% 
  st_transform(., crs = st_crs(r))


#get shapefile for united states with counties
co <- counties(state = NULL)

#take out places really far away
co <- co[!co$STATEFP == "02",]#Alaska
co <- co[!co$STATEFP == "60",] #American Samoa
co <- co[!co$STATEFP == "72",]# Puerto Rico
co <- co[!co$STATEFP == "78",] # Virgin Islands
co <- co[!co$STATEFP == "66",] # Guam
co <- co[!co$STATEFP == "15",] #HI
co <- co[!co$STATEFP == "69",] # Northern Mariana Islands

#plot counties
gg <- ggplot()
gg <- gg + geom_sf(data = co, color="black",
                   fill="white", size=0.25)
gg
#reproject crs of counties to raster
co <- co %>% 
  st_transform(., crs = st_crs(r))

#filter to US
spurp_data.sf <- st_intersection(spurp_data.sf, boundary)
plot(st_geometry(spurp_data.sf))

#extract climate data for pitcher locations
extract <- terra::extract(environ.stack, spurp_data.sf, fun = mean, na.rm=TRUE)
extract.df <- as.data.frame(extract)
names(extract.df)[5] <- "elevation"

#combine plant data with predictor variables
pred.resp <- cbind(extract.df, spurp_data.sf)

#remove rows we don't need
pred.resp <- pred.resp[,-(6:13)]

#add presence data (for rf and log)
pred.resp$pres <- "1"
pred.resp <- pred.resp[,-(6)]

#some spatial data presence points also (for maxent)
spurp_data.sf$pres <- "1"
pres.pts <- as(spurp_data.sf, Class = "Spatial")
head(pres.pts)
pres.pts <- pres.pts[,-(1:8)]

#make some random points in the US
#set the extent for the pitcher plant data to be where we collect bg points
bg <- randomPoints(environ.stack, 10000, ext=e)
bg <- as.data.frame(bg)
class(bg)
bg.sf <- st_as_sf(bg, coords = c("x", "y"), crs = "EPSG:4326")

bg.sf <- bg.sf %>% 
  st_transform(., crs = st_crs(r))

bg.sf$pres <- "0"

#extract background point values from rasters of predictor variables
bg.df <- extract(environ.stack, bg.sf, df = TRUE)
bg.df <- bg.df[,-(1)]
names(bg.df)[5] <- "elevation"

#these are the absence points
bg.df$pres <- "0"

bg.df <- as.data.frame(bg.df)
pred.resp <- as.data.frame(pred.resp)

#COMBINE PRES AND SIMULATED ABS POINTS!
presabs.df <- rbind(pred.resp, bg.df)

presabs.df$pres <- as.factor(presabs.df$pres)

#scale the predictors
presabs.df[,1:5] <- scale(presabs.df[,1:5])
pairs(presabs.df[,1:5])
```


## Results

### Logistic Regression Models

A logistic regression was used to model the binary presence and absence data in pitcher plant observations.  The variables were scaled prior to analysis. The global model compared the effect of all 5 variables on the presence of pitcher plants.  All 5 variables showed a significant effect (p< 0), temperature and precipitation had a positive effect on presence, while max temp, min temp, and elevation had negative effects on presence.  Model fit for this model was AUC: 0.8517.  When compared with the restricted model, the effect direction was the same, only sightly different values.  However using AUC again for model fit, the restricted model had an AUC = 0.7049.  When using K-fold cross validation (kfcv) the cross validated data scored a mean squared error (delta) that is very low and is similar to the global logistic model (0.1487134 0.1487087).


```{r logreg}

presabs.df.nona <- drop_na(presabs.df)
presabs.df.nona$pres <- as.factor(presabs.df.nona$pres)
###GLOBAL MODEL
#model using all the predictors
logistic.global <- glm(pres~temp + prec + max_temp + min_temp + elevation, family=binomial(link="logit"), data=presabs.df.nona)
logistic.global
summary(logistic.global)

#calculate probability of pres/abs for each predic. in test dataset
predicted.1 <- predict(logistic.global, presabs.df.nona, type="response")
#calculate AUC
pROC::auc(presabs.df.nona$pres, predicted.1) #AUC = 0.8517

# KFCV 
cv.err1 <- boot::cv.glm(presabs.df.nona,logistic.global, K = 10)
cv.err1$delta #0.1487134 0.1487087


#REDUCED MODEL
#model using two of the predictors
logistic.two <- glm(pres ~ prec + elevation, family=binomial(link="logit"), data=presabs.df.nona)
logistic.two
summary(logistic.two)

#calculate probability of default for each individual in test dataset
predicted.2 <- predict(logistic.two, presabs.df.nona, type="response")
#calculate AUC
pROC::auc(presabs.df.nona$pres, predicted.2) #AUC = 0.7049

# KFCV 
cv.err2 <- boot::cv.glm(presabs.df.nona,logistic.two, K = 10)
cv.err2$delta #0.1935652 0.1935632
cv.err2

```

### Random Forest Models

A random forest model was used to classify the binary presence and absence data in pitcher plant observations.  The variables were scaled prior to analysis and NAs were removed. The global model compared the effect of all 5 variables on the presence of pitcher plants.  All 5 variables were ranked by the model with elevation, max temp, and precipitation having the highest Mean Decrease GINI Index.  Model fit for this model was AUC: 0.9843.  When compared with the restricted model, the two variables had high Mean Decrease Gini Indices, but wasn't as informative as the global model and resulted in an AUC = 0.9424.  When using K-fold cross validation (kfcv) on the restricted model, the error was high (0.23) for the first variable (precipitation) and < 0.17 for elevation.  The global random forest model scored the best AUC of all 6 models so a confusion matrix was built to look at the occurrence of false positives and negatives in relation to correct predictions.  We found that out of 14832 samples, false negatives = 70, false positives = 11, and correct predictions occurred 99.5% of the time.


```{r RANFOR}
#GLOBAL MODEL
#random forest regression
glob.model <- pres ~ temp + prec + max_temp + min_temp + elevation
rf1 <- randomForest(glob.model, data=presabs.df.nona, na.rm = TRUE)
varImpPlot(rf1)

#AUC
rf1.roc<-roc(presabs.df.nona$pres,rf1$votes[,2])
plot(rf1.roc)
auc(rf1.roc) #0.9843

# KFCV 
#divide up the predictor and response
a <- presabs.df.nona
a$pres <- NULL
b <- presabs.df.nona$pres
rf1.cv <- randomForest::rfcv(a, b, cv.fold=10)
with(rf1.cv, plot(n.var, error.cv))

#REDUCED MODEL
#random forest regression
reg.model <- pres ~ prec + elevation
rf2 <- randomForest(reg.model, data = presabs.df.nona)
varImpPlot(rf2)

#AUC
rf2.roc<-roc(presabs.df.nona$pres,rf2$votes[,2])
plot(rf2.roc)
auc(rf2.roc) #0.9424

# KFCV 
#divide up the predictor and response
c <- presabs.df.nona
c$pres <- NULL
c$temp <- NULL
c$min_temp <- NULL
c$max_temp <- NULL
b <- presabs.df.nona$pres
rf2.cv <- randomForest::rfcv(c, b, cv.fold=10)
with(rf2.cv, plot(n.var, error.cv))


```

```{r confmat, eval=FALSE}

# confusion matrix for my best model (global random forest)
y_pred <- predict(rf1, newdata = presabs.df.nona[-6])
y_pred
cm <- table(presabs.df.nona[,6], y_pred)
cm

#false neg = 70
#false pos = 11
#correct = 9930 + 4821 = 14751/14832 = .9945388 pretty good!
```

### Maximum Entropy Models

The last set of models used maximum entropy (`maxent()` via `dismo`), similarly to the other models, this model was fit with a global and restricted set of predictors. The global model showed that out of the total percentage of the variation that could be explained via the model, precipitation explained 40% of that.  Next max temp showed the next highest at 28%, with min temp the lowest at <5%.  The AUC for this model was 0.9346028  Looking at just precipitation and temperature in the restricted model, precipitation contributed to 80% of the explanatory power and elevation <20%.  The AUC for the restricted model was slightly lower than the global model, at 0.8273883


```{r MAXENT}
#GLOBAL MODEL
max.fit1 <- dismo::maxent(environ.stack, pres.pts, bg)
plot(max.fit1)
dismo::response(max.fit1)

#evaluate model
e1 <- evaluate(max.fit1, p = pres.pts, a = bg, x = environ.stack)
e1 #0.9346028
plot(e1, 'ROC')


#REDUCED MODEL
pr <- raster::subset(environ.stack, 2, drop = FALSE)
elev <- raster::subset(environ.stack, 5, drop = FALSE)
short.stack <- stack(pr, elev)

max.fit2 <- maxent(short.stack, pres.pts, bg)
plot(max.fit2)
response(max.fit2)

#evaluate model
e2 <- evaluate(max.fit2, p = pres.pts, a = bg, x = short.stack)
e2 #0.8273883
plot(e2, 'ROC')

```



```{r kfcv, eval=FALSE}
#KFCV for maxent models
library(maxnet)
pres.x <- presabs.df.nona[presabs.df.nona[,6] == 1, 1:5]
back.x <- presabs.df.nona[presabs.df.nona[,6] == 0, 1:5]

eMAX<-list()
folds <- 10
kfold_pres <- kfold(pres.x, folds)
kfold_back <- kfold(back.x, folds)

for (i in 1:folds) {
  train <- pres.x[kfold_pres!= i,]
  test <- pres.x[kfold_pres == i,]
  backTrain<-back.x[kfold_back!=i,]
  backTest<- back.x[kfold_back==i,]
  dataTrain<-rbind(train,backTrain)
  dataTest<-rbind(test,backTest)
  maxnet_eval <- maxnet(dataTrain$pres, dataTrain[,1:5])
  eMAX[[i]] <- evaluate(p=dataTest[which(dataTest$pres==1),],a=dataTest[which(dataTest$pres==0),], maxnet_eval)
  plot(eMAX[[i]],'ROC')
}
##Error in glmnet::glmnet(x = mm, y = as.factor(p), family = "binomial",  : 
##number of elements in weights (0) not equal to the number of rows of x (13349)



```


```{r maxentkfcc2}

#Lets try a different way to do kfcv for maxent...
#install.packages("ecospat")
library(ecospat)
me.pred <- ecospat.cv.me(presabs.df.nona, names(presabs.df.nona)[6],
             names(presabs.df.nona)[-6], K = 10, cv.lim = 10, jack.knife = FALSE)

plot(me.pred)

```








```{r plot, mindepth}

#Variable Important and Depth Plot
#mean minimal depth, the smaller the number the more important the variable and the more observations in can group at lower branches
plot_min_depth_distribution(rf1)

```


## Discussion

Best AUC was reported for the global random forest model (0.98).  The distribution of minimal depth provides a visualization of which variables are the most important in terms of informing the model, variables with lower mean depth scores are able to group the most numbers of observations with the least branches.  In the case of our random forest global model, precipitation and max temperature were the most efficient at grouping observations (mean minimal depth, 1 and 1.1 respectively).Each model provided valuable information, the random forest model gave an easy and accurate way of determining variable importance and effect of including less variables.  This provides helpful information, especially when variables may be correlated.  Even though the logistic regression had a lower AUC than maximum entropy and random forest, the information it provides in terms of effect size and direction on the response variable provides a good tool for making predictions.  Especially if we used random forest to determine which variables to include in the logistic regression.  

I think using these models together helps to differentiate between variable importance, effect size, and predictive power.  Out of all of the models, random forest and the `glm` were the easiest for me to use, especially with the data and formula for the models and the k-fold cross validation.  `MaxEnt` was harder to understand what to put into the model and how to manipulate the data to perform kfcv.  Overall, the data I used to try and predict pitcher plant occurrence was informative.  It makes sense that precipitation would have a large effect on plant distribution because these plants are obligates of bog habitats and their survival depends on rainwater filling their pitchers.  I was surprised to see elevation also having a large effect and variable importance because despite most bogs occurring at sea level or close to, some *S. purpurea* have ranges that are at much higher elevations (high altitude bogs).
